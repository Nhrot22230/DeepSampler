{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nhrot22230/DeepSampler/blob/main/notebooks/colab_exploratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics\n",
        "!git clone https://github.com/Nhrot22230/DeepSampler\n",
        "!cd DeepSampler && make init"
      ],
      "metadata": {
        "id": "zsAamb1nupwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3f4SZ5MIu1U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRMFsPrBul4V"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Suponiendo que clonaste el repositorio en /content/DeepSampler\n",
        "project_root = os.path.join(os.getcwd(), \"DeepSampler\")\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfD5p85Xul4X"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import librosa\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "from src.pipelines import musdb_pipeline, train_pipeline, eval_pipeline, infer_pipeline\n",
        "from src.models import DeepSampler, SCUNet, SimpleUNet\n",
        "from src.utils.training import MultiSourceLoss, VGGFeatureLoss, MultiScaleLoss\n",
        "import numpy as np\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [20, 6]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCG8BQLDul4Z"
      },
      "outputs": [],
      "source": [
        "nfft = 2048\n",
        "hop_length = 512\n",
        "window = torch.hann_window(nfft)\n",
        "chunk_seconds = 2\n",
        "overlap = 0\n",
        "sr = 44100\n",
        "\n",
        "data_root = os.path.join(project_root, \"data\")\n",
        "musdb_root = os.path.join(data_root, \"musdb18hq\")\n",
        "\n",
        "if not os.path.exists(data_root):\n",
        "    raise FileNotFoundError(\n",
        "        \"No se encontr√≥ la carpeta data, por favor ejecute el script download_data.sh antes de ejecutar este script.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w713o04hul4a"
      },
      "outputs": [],
      "source": [
        "train_dataset = musdb_pipeline(\n",
        "    musdb_path=os.path.join(musdb_root, \"train\"),\n",
        "    nfft=nfft,\n",
        "    hop_length=hop_length,\n",
        "    window=window,\n",
        "    chunk_seconds=chunk_seconds,\n",
        "    overlap=overlap,\n",
        "    sample_rate=sr,\n",
        "    max_samples=100,\n",
        ")\n",
        "train_dataloader = torch.utils.data.DataLoader(\n",
        "    train_dataset, batch_size=4, shuffle=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUrL5fdtul4c"
      },
      "outputs": [],
      "source": [
        "test_dataset = musdb_pipeline(\n",
        "    musdb_path=os.path.join(musdb_root, \"test\"),\n",
        "    nfft=nfft,\n",
        "    hop_length=hop_length,\n",
        "    window=window,\n",
        "    chunk_seconds=chunk_seconds,\n",
        "    overlap=overlap,\n",
        "    sample_rate=sr,\n",
        "    max_samples=300,\n",
        ")\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDjLO1Dtul4e"
      },
      "outputs": [],
      "source": [
        "deep_sampler = DeepSampler()\n",
        "optimizer = optim.Adam(deep_sampler.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "criterion = MultiSourceLoss(\n",
        "    weights=[1, 1, 1, 1],\n",
        "    distance=\"l1\",\n",
        ")\n",
        "\n",
        "factor = 1\n",
        "epochs = 2 * factor\n",
        "p1_epochs = 1 * factor\n",
        "deep_sampler.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMji1Hc-ul4f"
      },
      "outputs": [],
      "source": [
        "history = train_pipeline(\n",
        "    model=deep_sampler,\n",
        "    dataloader=train_dataset,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    total_epochs=epochs,\n",
        "    phase1_epochs=p1_epochs,\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HB-E3JsJul4g"
      },
      "outputs": [],
      "source": [
        "# plot history = {\"epoch_loss\": [], \"learning_rate\": [], \"batch_losses\": []}\n",
        "plt.plot(history[\"epoch_loss\"])\n",
        "plt.title(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history[\"learning_rate\"])\n",
        "plt.title(\"Learning Rate\")\n",
        "plt.show()\n",
        "\n",
        "plt.plot(np.array(history[\"batch_losses\"]).flatten())\n",
        "plt.title(\"Batch Losses\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIqF56rdul4h"
      },
      "outputs": [],
      "source": [
        "test_folders = os.listdir(os.path.join(musdb_root, \"test\"))\n",
        "random_folder = np.random.choice(test_folders)\n",
        "\n",
        "audio_mixture = os.path.join(musdb_root, \"test\", random_folder, \"mixture.wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOo8l9INul4j"
      },
      "outputs": [],
      "source": [
        "sources = infer_pipeline(\n",
        "    model=deep_sampler,\n",
        "    mixture_path=audio_mixture,\n",
        "    sample_rate=44100,\n",
        "    chunk_seconds=chunk_seconds,\n",
        "    overlap=overlap,\n",
        "    n_fft=nfft,\n",
        "    hop_length=hop_length,\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKF10-hTul4k"
      },
      "outputs": [],
      "source": [
        "inst = [\"vocals\", \"drums\", \"bass\", \"other\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-tw6BJZZul4m"
      },
      "outputs": [],
      "source": [
        "for instrument in inst:\n",
        "    file_path = os.path.join(musdb_root, \"test\", random_folder, f\"{instrument}.wav\")\n",
        "    wav, _ = librosa.load(file_path, sr=44100)\n",
        "    plt.figure(figsize=(20, 6))\n",
        "    plt.plot(wav)\n",
        "    plt.title(instrument)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkjzJF6Kul4m"
      },
      "outputs": [],
      "source": [
        "for i, s in enumerate(inst):\n",
        "    plt.figure(figsize=(20, 6))\n",
        "    plt.plot(sources[s])\n",
        "    plt.title(s)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4pCPaEsul4n"
      },
      "outputs": [],
      "source": [
        "# Create experiments folder with checkpoints, logs and results\n",
        "experiments_path = os.path.join(project_root, \"experiments\")\n",
        "if not os.path.exists(experiments_path):\n",
        "    os.mkdir(experiments_path)\n",
        "\n",
        "experiment_name = \"deep_sampler\"\n",
        "experiment_path = os.path.join(experiments_path, experiment_name)\n",
        "if not os.path.exists(experiment_path):\n",
        "    os.mkdir(experiment_path)\n",
        "\n",
        "# Save model\n",
        "model_path = os.path.join(experiment_path, \"model.pth\")\n",
        "torch.save(deep_sampler.state_dict(), model_path)\n",
        "\n",
        "# Save history\n",
        "history_path = os.path.join(experiment_path, \"history.pth\")\n",
        "torch.save(history, history_path)\n",
        "\n",
        "# Save sources\n",
        "sources_path = os.path.join(experiment_path, \"sources.pth\")\n",
        "torch.save(sources, sources_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ia_ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.getcwd()\n",
    "while \"src\" not in os.listdir(project_root):\n",
    "    project_root = os.path.dirname(project_root)\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from src.pipelines import train_pipeline, infer_pipeline\n",
    "from src.models import SimpleUNet, SCUNet, DeepSampler\n",
    "from src.utils.data.dataset import MUSDB18Dataset\n",
    "from src.utils.training import (\n",
    "    MultiSourceLoss,\n",
    "    MultiScaleLoss,\n",
    ")\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "experiments_path = os.path.join(project_root, \"experiments\")\n",
    "data_root = os.path.join(project_root, \"data\")\n",
    "checkpoint_path = os.path.join(experiments_path, \"checkpoints\")\n",
    "scunet_path = os.path.join(checkpoint_path, \"scunet.pth\")\n",
    "results_path = os.path.join(experiments_path, \"results\")\n",
    "musdb_path = os.path.join(project_root, \"data\", \"musdb18hq\", \"test\")\n",
    "musdb_files = os.listdir(musdb_path)\n",
    "musdb_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_sampler = DeepSampler()\n",
    "x = torch.randn(1, 1, 1025, 173)  # (batch, channels, height, width)\n",
    "output = deep_sampler(x)  # Salida: (1, 4, 1025, 173)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MUSDB18Dataset(os.path.join(data_root, \"processed\", \"train\"))\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=8, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "mixture, _ = train_dataset.__getitem__(0)\n",
    "print(\"Sample input shape:\", mixture.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_sampler.to(device)\n",
    "weights = [3.0, 1.0, 1.0, 1.0]\n",
    "weights = [w / sum(weights) for w in weights]\n",
    "\n",
    "criterion = MultiSourceLoss(\n",
    "    weights=weights,\n",
    "    distance=\"l1\",\n",
    ")\n",
    "\n",
    "# Configuración del optimizador.\n",
    "# Se incrementó ligeramente el weight_decay para ayudar a prevenir overfitting.\n",
    "optimizer = optim.Adam(deep_sampler.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# Configuración del scheduler.\n",
    "# Opción 1: StepLR, que reduce la tasa de aprendizaje cada 10 épocas.\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "# Opción 2 (alternativa): ReduceLROnPlateau, que reduce la tasa de aprendizaje\n",
    "# cuando la pérdida de validación se estanca.\n",
    "# scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=5)\n",
    "\n",
    "# Parámetros de entrenamiento\n",
    "total_epochs = (\n",
    "    50  # Se recomienda aumentar el número de épocas para asegurar la convergencia.\n",
    ")\n",
    "phase1_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model, history = train_pipeline(\n",
    "    model=deep_sampler,\n",
    "    dataloader=train_loader,\n",
    "    device=device,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    total_epochs=total_epochs,\n",
    "    phase1_epochs=phase1_epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history losses\n",
    "# history = {\"epoch_loss\": [], \"learning_rate\": []}\n",
    "plt.plot(history[\"epoch_loss\"])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds = 30\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 512\n",
    "\n",
    "random_sample = np.random.choice(musdb_files)\n",
    "sample_path = os.path.join(musdb_path, random_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_path = os.path.join(sample_path, \"mixture.wav\")\n",
    "vocals_path = os.path.join(sample_path, \"vocals.wav\")\n",
    "bass_path = os.path.join(sample_path, \"bass.wav\")\n",
    "drums_path = os.path.join(sample_path, \"drums.wav\")\n",
    "other_path = os.path.join(sample_path, \"other.wav\")\n",
    "\n",
    "mixture, sr = librosa.load(mixture_path, sr=None)\n",
    "vocals, _ = librosa.load(vocals_path, sr=None)\n",
    "bass, _ = librosa.load(bass_path, sr=None)\n",
    "drums, _ = librosa.load(drums_path, sr=None)\n",
    "other, _ = librosa.load(other_path, sr=None)\n",
    "\n",
    "mixture = mixture[: int(seconds * sr)]\n",
    "vocals = vocals[: int(seconds * sr)]\n",
    "bass = bass[: int(seconds * sr)]\n",
    "drums = drums[: int(seconds * sr)]\n",
    "other = other[: int(seconds * sr)]\n",
    "\n",
    "mixture_stft = librosa.stft(mixture, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "vocals_stft = librosa.stft(vocals, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "bass_stft = librosa.stft(bass, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "drums_stft = librosa.stft(drums, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "other_stft = librosa.stft(other, n_fft=N_FFT, hop_length=HOP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_pipeline(\n",
    "    model=trained_model,\n",
    "    mixture_path=mixture_path,\n",
    "    output_path=os.path.join(results_path, f\"deep_sampler\"),\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_vocals_path = os.path.join(results_path, \"deep_sampler\", \"vocals.wav\")\n",
    "res_bass_path = os.path.join(results_path, \"deep_sampler\", \"bass.wav\")\n",
    "res_drums_path = os.path.join(results_path, \"deep_sampler\", \"drums.wav\")\n",
    "res_other_path = os.path.join(results_path, \"deep_sampler\", \"other.wav\")\n",
    "\n",
    "res_vocals, sr = librosa.load(res_vocals_path, sr=None)\n",
    "res_bass, _ = librosa.load(res_bass_path, sr=None)\n",
    "res_drums, _ = librosa.load(res_drums_path, sr=None)\n",
    "res_other, _ = librosa.load(res_other_path, sr=None)\n",
    "\n",
    "res_vocals = res_vocals[: int(seconds * sr)]\n",
    "res_bass = res_bass[: int(seconds * sr)]\n",
    "res_drums = res_drums[: int(seconds * sr)]\n",
    "res_other = res_other[: int(seconds * sr)]\n",
    "\n",
    "res_vocals_stft = librosa.stft(res_vocals, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "res_bass_stft = librosa.stft(res_bass, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "res_drums_stft = librosa.stft(res_drums, n_fft=N_FFT, hop_length=HOP_LENGTH)\n",
    "res_other_stft = librosa.stft(res_other, n_fft=N_FFT, hop_length=HOP_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.suptitle(f\"Expectativa: {os.path.basename(sample_path)}\")\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.title(\"Mixture\")\n",
    "plt.imshow(np.log1p(np.abs(mixture_stft)), aspect=\"auto\", origin=\"lower\")\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.title(\"Vocals\")\n",
    "plt.imshow(np.log1p(np.abs(vocals_stft)), aspect=\"auto\", origin=\"lower\")\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.title(\"Bass\")\n",
    "plt.imshow(np.log1p(np.abs(bass_stft)), aspect=\"auto\", origin=\"lower\")\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.title(\"Drums\")\n",
    "plt.imshow(np.log1p(np.abs(drums_stft)), aspect=\"auto\", origin=\"lower\")\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.title(\"Other\")\n",
    "plt.imshow(np.log1p(np.abs(other_stft)), aspect=\"auto\", origin=\"lower\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 10))\n",
    "plt.suptitle(\"Realidad\")\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.title(\"Mixture\")\n",
    "plt.imshow(\n",
    "    np.log1p(np.abs(res_bass_stft + res_drums_stft + res_other_stft + res_vocals_stft)),\n",
    "    aspect=\"auto\",\n",
    "    origin=\"lower\",\n",
    ")\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.title(\"Vocals\")\n",
    "plt.imshow(np.log1p(np.abs(res_vocals_stft)), aspect=\"auto\", origin=\"lower\")\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.title(\"Bass\")\n",
    "plt.imshow(np.log1p(np.abs(res_bass_stft)), aspect=\"auto\", origin=\"lower\")\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.title(\"Drums\")\n",
    "plt.imshow(np.log1p(np.abs(res_drums_stft)), aspect=\"auto\", origin=\"lower\")\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.title(\"Other\")\n",
    "plt.imshow(np.log1p(np.abs(res_other_stft)), aspect=\"auto\", origin=\"lower\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

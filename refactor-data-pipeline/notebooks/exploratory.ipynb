{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nhrot22230/DeepSampler/blob/feat%2Frefactor-data-pipeline/refactor-data-pipeline/notebooks/exploratory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Nhrot22230/DeepSampler\n",
        "!cd DeepSampler && git pull && git checkout feat/refactor-data-pipeline"
      ],
      "metadata": {
        "id": "7pdCOZ7s8GcE",
        "outputId": "184e65ed-d243-4640-98e2-99071f727acc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DeepSampler'...\n",
            "remote: Enumerating objects: 597, done.\u001b[K\n",
            "remote: Counting objects: 100% (176/176), done.\u001b[K\n",
            "remote: Compressing objects: 100% (133/133), done.\u001b[K\n",
            "remote: Total 597 (delta 76), reused 130 (delta 43), pack-reused 421 (from 1)\u001b[K\n",
            "Receiving objects: 100% (597/597), 4.23 MiB | 12.18 MiB/s, done.\n",
            "Resolving deltas: 100% (298/298), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd DeepSampler && make init"
      ],
      "metadata": {
        "collapsed": true,
        "id": "drq8O08o8Fmk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mmf0vkz_8BEU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "# Suponiendo que clonaste el repositorio en /content/DeepSampler\n",
        "project_root = os.path.join(os.getcwd(), \"DeepSampler\")\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from src.pipelines import musdb_pipeline, train_pipeline, eval_pipeline, infer_pipeline"
      ],
      "metadata": {
        "id": "h87GNaVLCaJW",
        "outputId": "7d0aa2b8-2387-4e3b-8300-0f43217f4a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'musdb_pipeline' from 'src.pipelines' (/content/DeepSampler/src/pipelines/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-17a9895d1051>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipelines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmusdb_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'musdb_pipeline' from 'src.pipelines' (/content/DeepSampler/src/pipelines/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jGunjtK18BEV",
        "outputId": "caee8d8d-2e37-466d-e125-93c12ae67d06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'musdb_pipeline' from 'src.pipelines' (/content/DeepSampler/src/pipelines/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-7f6a78dcbebf>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStepLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mReduceLROnPlateau\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipelines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmusdb_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_pipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfer_pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSCUNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSimpleUNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiSourceLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVGGFeatureLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiScaleLoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'musdb_pipeline' from 'src.pipelines' (/content/DeepSampler/src/pipelines/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "from src.pipelines import musdb_pipeline, train_pipeline, eval_pipeline, infer_pipeline\n",
        "from src.models import DeepSampler, SCUNet, SimpleUNet\n",
        "from src.utils.training import MultiSourceLoss, VGGFeatureLoss, MultiScaleLoss\n",
        "import numpy as np\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = [20, 6]\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0djtqzQE8BEV"
      },
      "outputs": [],
      "source": [
        "nfft = 2048\n",
        "hop_length = 512\n",
        "window = torch.hann_window(nfft)\n",
        "chunk_seconds = 2\n",
        "overlap = 0\n",
        "sr = 44100\n",
        "\n",
        "data_root = os.path.join(project_root, \"data\")\n",
        "musdb_root = os.path.join(data_root, \"musdb18hq\")\n",
        "\n",
        "if not os.path.exists(data_root):\n",
        "    raise FileNotFoundError(\n",
        "        \"No se encontr√≥ la carpeta data, por favor ejecute el script download_data.sh antes de ejecutar este script.\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kjIamha8BEW"
      },
      "outputs": [],
      "source": [
        "# train_dataset = musdb_pipeline(\n",
        "#     musdb_path=os.path.join(musdb_root, \"train\"),\n",
        "#     nfft=nfft,\n",
        "#     hop_length=hop_length,\n",
        "#     window=window,\n",
        "#     chunk_seconds=chunk_seconds,\n",
        "#     overlap=overlap,\n",
        "#     sample_rate=sr,\n",
        "# )\n",
        "# train_dataloader = torch.utils.data.DataLoader(\n",
        "#     train_dataset, batch_size=16, shuffle=True\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tpf9WCXU8BEW"
      },
      "outputs": [],
      "source": [
        "test_dataset = musdb_pipeline(\n",
        "    musdb_path=os.path.join(musdb_root, \"test\"),\n",
        "    nfft=nfft,\n",
        "    hop_length=hop_length,\n",
        "    window=window,\n",
        "    chunk_seconds=chunk_seconds,\n",
        "    overlap=overlap,\n",
        "    sample_rate=sr,\n",
        ")\n",
        "\n",
        "test_dataloader = torch.utils.data.DataLoader(\n",
        "    test_dataset, batch_size=16, shuffle=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Cbqi2l58BEW"
      },
      "outputs": [],
      "source": [
        "deep_sampler = DeepSampler(\n",
        "    input_channels=1,\n",
        "    output_channels=4,\n",
        "    base_channels=32,\n",
        "    depth=5,\n",
        "    dropout=0.1,\n",
        "    transformer_heads=4,\n",
        "    transformer_layers=4,\n",
        ")\n",
        "optimizer = optim.Adam(deep_sampler.parameters(), lr=1e-3, weight_decay=1e-5)\n",
        "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "criterion = MultiSourceLoss(\n",
        "    weights=[1, 1, 1, 1],\n",
        "    distance=\"l1\",\n",
        ")\n",
        "\n",
        "factor = 1\n",
        "epochs = 5 * factor\n",
        "p1_epochs = 2 * factor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGm8H7Gp8BEW"
      },
      "outputs": [],
      "source": [
        "train_pipeline(\n",
        "    model=deep_sampler,\n",
        "    dataloader=test_dataloader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    total_epochs=epochs,\n",
        "    phase1_epochs=p1_epochs,\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCdYKL-u8BEW"
      },
      "outputs": [],
      "source": [
        "test_folders = os.listdir(os.path.join(musdb_root, \"test\"))\n",
        "random_folder = np.random.choice(test_folders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FJckK9es8BEW"
      },
      "outputs": [],
      "source": [
        "sources = infer_pipeline(\n",
        "    model=deep_sampler,\n",
        "    mixture_path=os.path.join(musdb_root, \"test\", random_folder, \"mixture.wav\"),\n",
        "    sample_rate=44100,\n",
        "    chunk_seconds=chunk_seconds,\n",
        "    overlap=overlap,\n",
        "    n_fft=nfft,\n",
        "    hop_length=hop_length,\n",
        "    window=window,\n",
        "    device=device,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ia_ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}